#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
1. Docstrings –≤ Python –º–æ–¥—É–ª—è—Ö (—Ñ—É–Ω–∫—Ü–∏–∏, –∫–ª–∞—Å—Å—ã, –º–æ–¥—É–ª–∏)
2. README —Ñ–∞–π–ª—ã –∏ –∏—Ö –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
3. –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–¥–µ –∏ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ
4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–º—É –∫–æ–¥—É
5. –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –∏—Ö –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å

–†–µ–∑—É–ª—å—Ç–∞—Ç: documentation_analysis_report.md —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –æ—Ç—á–µ—Ç–æ–º
"""

import ast
import re
import sys
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from collections import defaultdict
import datetime

# –ò—Å–∫–ª—é—á–∞–µ–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
EXCLUDE_DIRS = {'.git', 'venv', '__pycache__', 'allure-results', 'logs', 'screenshots', '.pytest_cache'}

class DocumentationAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø–æ–ª–Ω–æ—Ç—ã."""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.python_files: List[Path] = []
        self.markdown_files: List[Path] = []
        self.issues: List[str] = []
        self.stats = {
            'total_functions': 0,
            'documented_functions': 0,
            'total_classes': 0,
            'documented_classes': 0,
            'total_modules': 0,
            'documented_modules': 0,
            'readme_files': 0,
            'outdated_docs': 0
        }
        
    def scan_project(self) -> None:
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
        print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞...")
        
        for file_path in self.project_root.rglob("*"):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            if any(excluded in file_path.parts for excluded in EXCLUDE_DIRS):
                continue
                
            if file_path.suffix == '.py' and file_path.is_file():
                self.python_files.append(file_path)
            elif file_path.suffix.lower() in {'.md', '.rst', '.txt'} and file_path.is_file():
                self.markdown_files.append(file_path)
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ Python —Ñ–∞–π–ª–æ–≤: {len(self.python_files)}")
        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(self.markdown_files)}")
    
    def analyze_python_docstrings(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç docstrings –≤ Python —Ñ–∞–π–ª–∞—Ö."""
        print("üìù –ê–Ω–∞–ª–∏–∑ docstrings...")
        
        docstring_stats = {
            'files_analyzed': 0,
            'modules_with_docstrings': 0,
            'functions_without_docstrings': [],
            'classes_without_docstrings': [],
            'poor_quality_docstrings': [],
            'good_examples': []
        }
        
        for py_file in self.python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                try:
                    tree = ast.parse(content)
                    docstring_stats['files_analyzed'] += 1
                    
                    # –ê–Ω–∞–ª–∏–∑ docstring –º–æ–¥—É–ª—è
                    module_docstring = ast.get_docstring(tree)
                    if module_docstring:
                        docstring_stats['modules_with_docstrings'] += 1
                        self.stats['documented_modules'] += 1
                    
                    self.stats['total_modules'] += 1
                    
                    # –ê–Ω–∞–ª–∏–∑ —Ñ—É–Ω–∫—Ü–∏–π –∏ –∫–ª–∞—Å—Å–æ–≤
                    for node in ast.walk(tree):
                        if isinstance(node, ast.FunctionDef):
                            self.stats['total_functions'] += 1
                            docstring = ast.get_docstring(node)
                            
                            if docstring:
                                self.stats['documented_functions'] += 1
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ docstring
                                if self._is_good_docstring(docstring):
                                    docstring_stats['good_examples'].append({
                                        'file': str(py_file.relative_to(self.project_root)),
                                        'function': node.name,
                                        'quality': 'high'
                                    })
                                elif self._is_poor_docstring(docstring):
                                    docstring_stats['poor_quality_docstrings'].append({
                                        'file': str(py_file.relative_to(self.project_root)),
                                        'function': node.name,
                                        'issue': 'poor_quality'
                                    })
                            else:
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º __init__, __str__ –∏ –¥—Ä—É–≥–∏–µ magic methods –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
                                if not node.name.startswith('_'):
                                    docstring_stats['functions_without_docstrings'].append({
                                        'file': str(py_file.relative_to(self.project_root)),
                                        'function': node.name
                                    })
                        
                        elif isinstance(node, ast.ClassDef):
                            self.stats['total_classes'] += 1
                            docstring = ast.get_docstring(node)
                            
                            if docstring:
                                self.stats['documented_classes'] += 1
                            else:
                                docstring_stats['classes_without_docstrings'].append({
                                    'file': str(py_file.relative_to(self.project_root)),
                                    'class': node.name
                                })
                
                except SyntaxError:
                    print(f"‚ö†Ô∏è –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ {py_file}")
                    
            except (UnicodeDecodeError, FileNotFoundError) as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {py_file}: {e}")
        
        return docstring_stats
    
    def _is_good_docstring(self, docstring: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ docstring."""
        if len(docstring) < 20:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ö–æ—Ä–æ—à–µ–≥–æ docstring
        has_description = len(docstring.split('\n')[0]) > 10
        has_args = 'Args:' in docstring or 'Parameters:' in docstring
        has_returns = 'Returns:' in docstring or 'Return:' in docstring
        has_examples = 'Example' in docstring or 'Usage:' in docstring
        
        return has_description and (has_args or has_returns)
    
    def _is_poor_docstring(self, docstring: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ docstring."""
        if len(docstring) < 10:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã-–ø—É—Å—Ç—ã—à–∫–∏
        poor_patterns = [
            'TODO', 'FIXME', 'XXX',
            'Function to', 'Method to',
            'This function', 'This method',
            '...', 'pass', 'None'
        ]
        
        return any(pattern in docstring for pattern in poor_patterns)
    
    def analyze_readme_files(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç README —Ñ–∞–π–ª—ã –∏ –∏—Ö –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å."""
        print("üìã –ê–Ω–∞–ª–∏–∑ README —Ñ–∞–π–ª–æ–≤...")
        
        readme_stats = {
            'readme_files': [],
            'outdated_readmes': [],
            'good_readmes': [],
            'missing_sections': []
        }
        
        for md_file in self.markdown_files:
            if 'readme' in md_file.name.lower():
                self.stats['readme_files'] += 1
                readme_stats['readme_files'].append(str(md_file.relative_to(self.project_root)))
                
                try:
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É README
                    sections = self._analyze_readme_structure(content)
                    missing = self._check_missing_readme_sections(content)
                    
                    if missing:
                        readme_stats['missing_sections'].append({
                            'file': str(md_file.relative_to(self.project_root)),
                            'missing': missing
                        })
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å (–Ω–∞–ª–∏—á–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Å—Å—ã–ª–æ–∫/–ø—É—Ç–µ–π)
                    if self._is_outdated_readme(content):
                        readme_stats['outdated_readmes'].append(str(md_file.relative_to(self.project_root)))
                        self.stats['outdated_docs'] += 1
                    else:
                        readme_stats['good_readmes'].append(str(md_file.relative_to(self.project_root)))
                
                except (UnicodeDecodeError, FileNotFoundError) as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è README {md_file}: {e}")
        
        return readme_stats
    
    def _analyze_readme_structure(self, content: str) -> List[str]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É README —Ñ–∞–π–ª–∞."""
        lines = content.split('\n')
        sections = []
        
        for line in lines:
            if line.startswith('#'):
                sections.append(line.strip())
        
        return sections
    
    def _check_missing_readme_sections(self, content: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã –≤ README."""
        essential_sections = [
            'installation', 'setup', 'usage', 'example',
            'requirements', 'dependencies'
        ]
        
        content_lower = content.lower()
        missing = []
        
        for section in essential_sections:
            if section not in content_lower:
                missing.append(section)
        
        return missing
    
    def _is_outdated_readme(self, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å README."""
        outdated_patterns = [
            'src/', 'old_', 'deprecated', 'legacy',
            'TODO', 'FIXME', 'coming soon'
        ]
        
        return any(pattern in content for pattern in outdated_patterns)
    
    def analyze_code_comments(self) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ –∫–æ–¥–µ."""
        print("üí¨ –ê–Ω–∞–ª–∏–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ –∫–æ–¥–µ...")
        
        comment_stats = {
            'files_with_comments': 0,
            'total_comments': 0,
            'poor_comments': [],
            'good_comments': [],
            'todo_comments': []
        }
        
        for py_file in self.python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                file_has_comments = False
                
                for i, line in enumerate(lines, 1):
                    line = line.strip()
                    
                    # –ò—â–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                    if line.startswith('#') and not line.startswith('#!/'):
                        comment_stats['total_comments'] += 1
                        file_has_comments = True
                        
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
                        if self._is_todo_comment(line):
                            comment_stats['todo_comments'].append({
                                'file': str(py_file.relative_to(self.project_root)),
                                'line': i,
                                'comment': line
                            })
                        elif self._is_poor_comment(line):
                            comment_stats['poor_comments'].append({
                                'file': str(py_file.relative_to(self.project_root)),
                                'line': i,
                                'comment': line
                            })
                        elif self._is_good_comment(line):
                            comment_stats['good_comments'].append({
                                'file': str(py_file.relative_to(self.project_root)),
                                'line': i,
                                'comment': line
                            })
                
                if file_has_comments:
                    comment_stats['files_with_comments'] += 1
                    
            except (UnicodeDecodeError, FileNotFoundError) as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {py_file}: {e}")
        
        return comment_stats
    
    def _is_todo_comment(self, comment: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π TODO."""
        todo_patterns = ['TODO', 'FIXME', 'XXX', 'HACK', 'BUG']
        return any(pattern in comment.upper() for pattern in todo_patterns)
    
    def _is_poor_comment(self, comment: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è."""
        if len(comment) < 10:
            return True
        
        poor_patterns = [
            '# fix this', '# temp', '# delete', '# remove',
            '# test', '# debug', '#print', '# 123'
        ]
        
        return any(pattern in comment.lower() for pattern in poor_patterns)
    
    def _is_good_comment(self, comment: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è."""
        if len(comment) < 15:
            return False
        
        # –•–æ—Ä–æ—à–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ–±—ä—è—Å–Ω—è—é—Ç "–ø–æ—á–µ–º—É", –∞ –Ω–µ "—á—Ç–æ"
        good_indicators = [
            '–æ–±—ä—è—Å–Ω—è', '–ø—Ä–∏—á–∏–Ω–∞', '–≤–∞–∂–Ω–æ', '–æ–±—Ö–æ–¥', '–∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç',
            'explains', 'reason', 'important', 'workaround', 'fixes',
            '–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å'
        ]
        
        return any(indicator in comment.lower() for indicator in good_indicators)
    
    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
        docstring_stats = self.analyze_python_docstrings()
        readme_stats = self.analyze_readme_files()
        comment_stats = self.analyze_code_comments()
        
        report = []
        report.append("# üìö –û—Ç—á–µ—Ç –æ–± –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞")
        report.append("")
        report.append(f"**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ Python —Ñ–∞–π–ª–æ–≤:** {len(self.python_files)}")
        report.append(f"**–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:** {len(self.markdown_files)}")
        report.append("")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report.append("## üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        report.append("")
        
        # Docstrings —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        func_coverage = (self.stats['documented_functions'] / max(self.stats['total_functions'], 1)) * 100
        class_coverage = (self.stats['documented_classes'] / max(self.stats['total_classes'], 1)) * 100
        module_coverage = (self.stats['documented_modules'] / max(self.stats['total_modules'], 1)) * 100
        
        report.append("### üìù –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–¥–∞")
        report.append("")
        report.append(f"- **–§—É–Ω–∫—Ü–∏–∏ —Å docstrings:** {self.stats['documented_functions']}/{self.stats['total_functions']} ({func_coverage:.1f}%)")
        report.append(f"- **–ö–ª–∞—Å—Å—ã —Å docstrings:** {self.stats['documented_classes']}/{self.stats['total_classes']} ({class_coverage:.1f}%)")
        report.append(f"- **–ú–æ–¥—É–ª–∏ —Å docstrings:** {self.stats['documented_modules']}/{self.stats['total_modules']} ({module_coverage:.1f}%)")
        report.append("")
        
        # README —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report.append("### üìã README —Ñ–∞–π–ª—ã")
        report.append("")
        report.append(f"- **–í—Å–µ–≥–æ README —Ñ–∞–π–ª–æ–≤:** {self.stats['readme_files']}")
        report.append(f"- **–£—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {self.stats['outdated_docs']}")
        report.append(f"- **–ê–∫—Ç—É–∞–ª—å–Ω—ã—Ö README:** {len(readme_stats['good_readmes'])}")
        report.append("")
        
        # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report.append("### üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –∫–æ–¥–µ")
        report.append("")
        report.append(f"- **–§–∞–π–ª–æ–≤ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏:** {comment_stats['files_with_comments']}")
        report.append(f"- **–í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:** {comment_stats['total_comments']}")
        report.append(f"- **TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:** {len(comment_stats['todo_comments'])}")
        report.append(f"- **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:** {len(comment_stats['good_comments'])}")
        report.append("")
        
        # –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏
        report.append("## ‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏")
        report.append("")
        
        if docstring_stats['functions_without_docstrings']:
            report.append("### üîç –§—É–Ω–∫—Ü–∏–∏ –±–µ–∑ docstrings")
            report.append("")
            for item in docstring_stats['functions_without_docstrings'][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                report.append(f"- `{item['file']}`: —Ñ—É–Ω–∫—Ü–∏—è `{item['function']}`")
            
            if len(docstring_stats['functions_without_docstrings']) > 10:
                remaining = len(docstring_stats['functions_without_docstrings']) - 10
                report.append(f"- ... –∏ –µ—â–µ {remaining} —Ñ—É–Ω–∫—Ü–∏–π")
            report.append("")
        
        if docstring_stats['classes_without_docstrings']:
            report.append("### üì¶ –ö–ª–∞—Å—Å—ã –±–µ–∑ docstrings")
            report.append("")
            for item in docstring_stats['classes_without_docstrings'][:5]:
                report.append(f"- `{item['file']}`: –∫–ª–∞—Å—Å `{item['class']}`")
            report.append("")
        
        if comment_stats['todo_comments']:
            report.append("### üìù TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
            report.append("")
            for item in comment_stats['todo_comments'][:5]:
                report.append(f"- `{item['file']}:{item['line']}`: {item['comment']}")
            report.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é")
        report.append("")
        
        if func_coverage < 70:
            report.append("### üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –£–ª—É—á—à–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–π")
            report.append("")
            report.append("- –î–æ–±–∞–≤–∏—Ç—å docstrings –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
            report.append("- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Google/NumPy —Å—Ç–∏–ª—å docstrings")
            report.append("- –í–∫–ª—é—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ Args –∏ Returns")
            report.append("")
        
        if readme_stats['missing_sections']:
            report.append("### üìã –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –£–ª—É—á—à–µ–Ω–∏–µ README —Ñ–∞–π–ª–æ–≤")
            report.append("")
            for item in readme_stats['missing_sections']:
                report.append(f"- `{item['file']}`: –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–¥–µ–ª—ã {', '.join(item['missing'])}")
            report.append("")
        
        report.append("### üîß –û–±—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è")
        report.append("")
        report.append("1. **–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è docstrings** - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–¥–∏–Ω—ã–π —Å—Ç–∏–ª—å")
        report.append("2. **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README** - —É–±—Ä–∞—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ —Å—Å—ã–ª–∫–∏")
        report.append("3. **–£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤** - –æ–±—ä—è—Å–Ω—è—Ç—å '–ø–æ—á–µ–º—É', –∞ –Ω–µ '—á—Ç–æ'")
        report.append("4. **–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è** - –¥–æ–±–∞–≤–∏—Ç—å –≤ docstrings")
        report.append("")
        
        # –•–æ—Ä–æ—à–∏–µ –ø—Ä–∏–º–µ—Ä—ã
        if docstring_stats['good_examples']:
            report.append("## ‚úÖ –•–æ—Ä–æ—à–∏–µ –ø—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
            report.append("")
            for item in docstring_stats['good_examples'][:5]:
                report.append(f"- `{item['file']}`: —Ñ—É–Ω–∫—Ü–∏—è `{item['function']}`")
            report.append("")
        
        return "\n".join(report)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
    project_root = Path.cwd()
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
    print(f"üìÇ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {project_root}")
    print("=" * 50)
    
    analyzer = DocumentationAnalyzer(project_root)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
    analyzer.scan_project()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = analyzer.generate_report()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_path = project_root / "documentation_analysis_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("=" * 50)
    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"üìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
    print(f"üìù –§—É–Ω–∫—Ü–∏–π —Å docstrings: {analyzer.stats['documented_functions']}/{analyzer.stats['total_functions']}")
    print(f"üì¶ –ö–ª–∞—Å—Å–æ–≤ —Å docstrings: {analyzer.stats['documented_classes']}/{analyzer.stats['total_classes']}")
    print(f"üìã README —Ñ–∞–π–ª–æ–≤: {analyzer.stats['readme_files']}")


if __name__ == "__main__":
    main()